{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbe11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import tkinter as tk\n",
    "from PIL import Image,ImageTk\n",
    "root=Tk()\n",
    "def abt():\n",
    "    \n",
    "    nwin=Toplevel(root)\n",
    "    nwin.title(\"EMOTION ABOUT\")\n",
    "    nwin.geometry(\"700x400+0+0\")\n",
    "    nwin.resizable(False,False)\n",
    "    nwin.configure(bg=\"#FFFF33\")\n",
    "    fnt=(\"Times\", \"40\",\"bold\")\n",
    "    lbl1=Label( nwin,text=\"Face Emotion Detection\",font=fnt, fg=\"#800000\",bg=\"#893BFF\")\n",
    "    lbl1.pack()\n",
    "    frm=Frame(nwin)\n",
    "    frm.pack(side=TOP ,pady=50 )\n",
    "    fnt2=(\"Times\", \"12\",\" italic\")\n",
    "    Fact=\"\"\"Facial emotion recognition is an AI technology used to analyse a personâ€™s face and interpret their expressions.Using these analyses and interpretations,the emotion a person is experiencing can be concluded with the use of technology.\n",
    "    \n",
    "Emotion recognition can be done using images and live video capturing via camera in the software. \n",
    "    *Created By Amit Pandey SRMCEM\"\"\"\n",
    "    T = Text(frm, height = 8, width =81,font=fnt2,fg=\"black\",bg=\"white\",padx=2,pady=10)\n",
    "    T.pack()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    T.insert(tk.END, Fact)\n",
    "    fnt3=(\"Times\", \"25\",\"bold\")\n",
    "    btn2=Button(nwin,text=\"Exit\",command=lambda:nwin.destroy(),font=fnt3,fg=\"#800000\",bg=\"#893BFF\",borderwidth = 0)\n",
    "    btn2.pack(side=tk.BOTTOM, padx=10,pady=10)\n",
    "def openwebcam():\n",
    "    faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap=cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError('cannot open webcam')\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        res=DeepFace.analyze(frame,actions = ['gender'],enforce_detection=False)\n",
    "        result=DeepFace.analyze(frame,actions = ['emotion'],enforce_detection=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        faces=faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x, y),(x+w, y+h),(0,255,0),2)\n",
    "\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        cv2.putText(frame, res[\"gender\"],(50,50),font,3,\n",
    "                   (0,0,222),2,cv2.LINE_4)\n",
    "        cv2.putText(frame, result['dominant_emotion'],(50,100),font,3,\n",
    "                   (1222,220,341),2,cv2.LINE_4)\n",
    "\n",
    "\n",
    "        cv2.imshow('Output video',frame)\n",
    "\n",
    "        if cv2.waitKey(2) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "def analyse():\n",
    "    faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    fln= filedialog.askopenfilename(initialdir=os.getcwd(),title=\"Select Image FILE\",filetypes=((\"JPG File\",\"*.jpeg\"),(\"PNG file\",\"*.png\"),(\"All Files\",\"*.*\")))\n",
    "    img=cv2.imread(fln)\n",
    "    res=DeepFace.analyze(img)\n",
    "    \n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceCascade.detectMultiScale(gray,1.1,4)\n",
    "\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x, y),(x+w, y+h),(0,255,0),2)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    cv2.putText(img, res['dominant_emotion'],(50,250),font,3,(0,0,222),2,cv2.LINE_4)\n",
    "    cv2.putText(img, res['gender'],(50,150),font,3,(0,1200,0),2,cv2.LINE_4)\n",
    "\n",
    "\n",
    "    cv2.imshow('My image',img)\n",
    "\n",
    "        \n",
    "    \n",
    "    lbl.image=img \n",
    "    return img\n",
    "\n",
    "bg=ImageTk.PhotoImage(file=\"bg.png\")\n",
    "label1 = Label( root)\n",
    "label1.place(x = 0, y = 0)\n",
    "\n",
    "lbl=Label( root)\n",
    "lbl.pack()\n",
    "frm=Frame(root,bg = \"#88cffa\")\n",
    "frm.pack(side=BOTTOM,padx=60)\n",
    "frm1=Frame(root,bg = \"#88cffa\")\n",
    "frm1.pack(side=TOP,padx=260)\n",
    "fnt=(\"Helvetica\", \"16\",\"bold italic\")\n",
    "btn=Button(frm,text=\"Start detection\",command=openwebcam,font=fnt,fg=\"#C70039\",bg=\"white\",borderwidth = 0)\n",
    "btn.pack(side=tk.LEFT,padx=10,pady=10)\n",
    "btn=Button(frm,text=\"Analyse Image\",command=analyse,font=fnt,fg=\"#C70039\",bg=\"white\",borderwidth = 0)\n",
    "btn.pack(side=tk.LEFT,padx=10,pady=10)\n",
    "btn=Button(frm1,text=\"About\",command=abt,font=fnt,fg=\"#C70039\",bg=\"white\",borderwidth = 0)\n",
    "btn.pack(side=TOP,padx=10,pady=10)\n",
    "btn2=Button(frm,text=\"Exit\",command=lambda:root.destroy(),font=fnt,fg=\"#C70039\",bg=\"white\",borderwidth = 0)\n",
    "btn2.pack(side=tk.LEFT, padx=10,pady=10)\n",
    "root.title(\"Browse Image\")\n",
    "root.geometry(\"700x400+0+0\")\n",
    "root.resizable(False,False)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3feefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d9e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
